{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 각종 설정\n",
    "모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from chrisbase.io import BaseProjectEnv\n",
    "from ratsnlp.nlpbook.classification.arguments import ClassificationDeployArguments\n",
    "\n",
    "config = ClassificationDeployArguments(\n",
    "    env=BaseProjectEnv(project_name=\"DeepKorean\"),\n",
    "    pretrained_model_path=\"model/pretrained/KcBERT-Base\",\n",
    "    downstream_model_home=\"model/finetuned/nsmc\",\n",
    "    downstream_model_file=None,\n",
    "    max_seq_length=128,\n",
    ").save_working_config()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   ClassificationDeployArguments                                                      value\n0                   env.env_type                                             BaseProjectEnv\n1                   env.hostname                                                      dl012\n2                   env.hostaddr                                             129.254.182.78\n3                env.python_path  /data/dlt/mambaforge/envs/DeepKorean-23.03/bin/python3.10\n4               env.project_name                                                 DeepKorean\n5               env.working_path                            /data/dlt/proj/DeepKorean-23.03\n6               env.running_file                                 runs/1-doc_cls-infer.ipynb\n7          pretrained_model_path                               model/pretrained/KcBERT-Base\n8          downstream_model_home                                       model/finetuned/nsmc\n9          downstream_model_file                  epoch=0-val_loss=0.246-val_acc=0.899.ckpt\n10          downstream_task_name                                    document-classification\n11                max_seq_length                                                        128\n12           working_config_file                                       1-doc_cls-infer.json",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ClassificationDeployArguments</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>env.env_type</td>\n      <td>BaseProjectEnv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>env.hostname</td>\n      <td>dl012</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>env.hostaddr</td>\n      <td>129.254.182.78</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>env.python_path</td>\n      <td>/data/dlt/mambaforge/envs/DeepKorean-23.03/bin/python3.10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>env.project_name</td>\n      <td>DeepKorean</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>env.working_path</td>\n      <td>/data/dlt/proj/DeepKorean-23.03</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>env.running_file</td>\n      <td>runs/1-doc_cls-infer.ipynb</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>pretrained_model_path</td>\n      <td>model/pretrained/KcBERT-Base</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>downstream_model_home</td>\n      <td>model/finetuned/nsmc</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>downstream_model_file</td>\n      <td>epoch=0-val_loss=0.246-val_acc=0.899.ckpt</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>downstream_task_name</td>\n      <td>document-classification</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max_seq_length</td>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>working_config_file</td>\n      <td>1-doc_cls-infer.json</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "config = Path(config)\n",
    "assert config.exists(), f\"No config file: {config}\"\n",
    "args = ClassificationDeployArguments.from_json(config.read_text())\n",
    "args.as_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 로딩\n",
    "파인튜닝을 마친 모델과 토크나이저를 읽어 들입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n      (position_embeddings): Embedding(300, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "fine_tuned_model_ckpt = torch.load(\n",
    "    Path(args.downstream_model_home) / args.downstream_model_file,\n",
    "    map_location=torch.device(\"cpu\")\n",
    ")\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    args.pretrained_model_path,\n",
    "    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),\n",
    ")\n",
    "model = BertForSequenceClassification(pretrained_model_config)\n",
    "model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "BertTokenizer(name_or_path='model/pretrained/KcBERT-Base', vocab_size=30000, model_max_length=300, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.pretrained_model_path,\n",
    "    do_lower_case=False,\n",
    ")\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 인퍼런스 함수 선언\n",
    "인퍼런스 함수를 선언합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def inference_fn(sentence):\n",
    "    inputs = tokenizer(\n",
    "        [sentence],\n",
    "        max_length=args.max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})\n",
    "        prob = outputs.logits.softmax(dim=1)\n",
    "        positive_prob = round(prob[0][1].item(), 4)\n",
    "        negative_prob = round(prob[0][0].item(), 4)\n",
    "        pred = \"긍정 (positive)\" if torch.argmax(prob) == 1 else \"부정 (negative)\"\n",
    "    return {\n",
    "        'sentence': sentence,\n",
    "        'prediction': pred,\n",
    "        'positive_data': f\"긍정 {positive_prob}\",\n",
    "        'negative_data': f\"부정 {negative_prob}\",\n",
    "        'positive_width': f\"{positive_prob * 100}%\",\n",
    "        'negative_width': f\"{negative_prob * 100}%\",\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 웹서비스 개시\n",
    "아래처럼 실행해 인퍼런스 함수를 웹서비스로 만듭니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'ratsnlp.nlpbook.classification.deploy'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001B[33mPress CTRL+C to quit\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dlt/proj/DeepKorean-23.03/ngrok/ngrok3 http 5000\n",
      " * Running on https://5f5a-129-254-182-78.jp.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Mar/2023 04:36:26] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2023 04:36:27] \"\u001B[33mGET /favicon.ico HTTP/1.1\u001B[0m\" 404 -\n",
      "127.0.0.1 - - [22/Mar/2023 04:36:30] \"POST /api HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from ratsnlp.nlpbook.classification.deploy import get_web_service_app\n",
    "\n",
    "service = get_web_service_app(inference_fn, ngrok_home=args.env.working_path)\n",
    "service.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
